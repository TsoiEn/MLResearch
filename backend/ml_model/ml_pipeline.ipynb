{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Disease Fever Cough Fatigue Difficulty Breathing  Age  Gender  \\\n",
      "0    Influenza   Yes    No     Yes                  Yes   19  Female   \n",
      "1  Common Cold    No   Yes     Yes                   No   25  Female   \n",
      "2       Eczema    No   Yes     Yes                   No   25  Female   \n",
      "3       Asthma   Yes   Yes      No                  Yes   25    Male   \n",
      "4       Asthma   Yes   Yes      No                  Yes   25    Male   \n",
      "\n",
      "  Blood Pressure Cholesterol Level Outcome Variable  \n",
      "0            Low            Normal         Positive  \n",
      "1         Normal            Normal         Negative  \n",
      "2         Normal            Normal         Negative  \n",
      "3         Normal            Normal         Positive  \n",
      "4         Normal            Normal         Positive  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 349 entries, 0 to 348\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   Disease               349 non-null    object\n",
      " 1   Fever                 349 non-null    object\n",
      " 2   Cough                 349 non-null    object\n",
      " 3   Fatigue               349 non-null    object\n",
      " 4   Difficulty Breathing  349 non-null    object\n",
      " 5   Age                   349 non-null    int64 \n",
      " 6   Gender                349 non-null    object\n",
      " 7   Blood Pressure        349 non-null    object\n",
      " 8   Cholesterol Level     349 non-null    object\n",
      " 9   Outcome Variable      349 non-null    object\n",
      "dtypes: int64(1), object(9)\n",
      "memory usage: 27.4+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/home/tsoien/github/MLResearch/backend/data/Disease_symptom_and_patient_profile_dataset.csv')\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Check dataset information\n",
    "print(df.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target variable (y)\n",
    "target_column = 'Outcome Variable'\n",
    "X = df.drop(columns=[target_column])  # Drop the target column to keep features\n",
    "y = df[target_column]  # Target column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed Data Shape: (349, 133)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Identify categorical and numeric columns\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns.tolist()\n",
    "numeric_columns = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Create preprocessing pipelines\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Combine into a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_columns),\n",
    "        ('cat', categorical_transformer, categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Preprocess the data\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "\n",
    "# Check the shape of the preprocessed data\n",
    "print(\"Preprocessed Data Shape:\", X_preprocessed.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Size: (279, 133)\n",
      "Testing Set Size: (70, 133)\n"
     ]
    }
   ],
   "source": [
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Check the sizes of splits\n",
    "print(\"Training Set Size:\", X_train.shape)\n",
    "print(\"Testing Set Size:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to /home/tsoien/github/MLResearch/backend/ml_model/model.joblib\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Random Forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model\n",
    "model_path = '/home/tsoien/github/MLResearch/backend/ml_model/model.joblib'\n",
    "joblib.dump(rf_model, model_path)\n",
    "print(f\"Model saved to {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.81\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.74      0.87      0.80        30\n",
      "    Positive       0.89      0.78      0.83        40\n",
      "\n",
      "    accuracy                           0.81        70\n",
      "   macro avg       0.81      0.82      0.81        70\n",
      "weighted avg       0.82      0.81      0.82        70\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
